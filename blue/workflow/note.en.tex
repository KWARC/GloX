\documentclass[12pt]{bluenote}
\usepackage[show]{ed}
% \usepackage{listings}
% \lstset{basicstyle=\sf,columns=fullflexible}
\usepackage[hyperref,backend=bibtex,style=alphabetic]{biblatex}
\addbibresource{kwarcpubs.bib}
\addbibresource{extpubs.bib}
\addbibresource{kwarccrossrefs.bib}
\addbibresource{extcrossrefs.bib}
\usepackage{stex-logo}
\usepackage{hyperref}
\usepackage{cleveref}

\title{The \FAUstairs Glossary Extraction and Curation Process}
\author{Michael Kohlhase\\
  Computer Science, FAU Erlangen-N\"urnberg\\
  \url{http://kwarc.info/kohlhase}}

\def\defemph#1{\textbf{#1}}
\def\FAUstairs{\textsf{FAUstairs}\xspace}
\blueProject{\FAUstairs}
\def\GloX{\textsf{GloX}\xspace}
\def\studon{\textsf{StudOn}\xspace}
\def\campo{\textsf{Campo}\xspace}
\def\DIP{\textsf{DIP}\xspace}
\def\FLAMS{\textsf{FLAMS}\xspace}
\def\FloDown{\textsf{FloDown}\xspace}
\def\ALeA{\textsf{ALeA}\xspace}

\begin{document}
\maketitle
\begin{abstract}
  We describe the initial ideas for the \FAUstairs glossary extraction and curation
  process and the workflows and tooling we envision to supports it.

  This blue note is (supposed to be) a living document that describes the current state of
  the discussion, to serve as an implementation guide and initial documentation for the
  \GloX tool ecosystem.
\end{abstract}
\tableofcontents\newpage

\section{Introduction}\label{sec:intro}

A Central part of the \FAUstairs project (``Formative Assessment for Universities:
Strategic Application of Innovative Methods to Raise Study Success Rates'' see
\url{https://faustairs.fau.de}) is the development and curation of a \defemph{domain
  model} -- i.e. a set of key concepts and their definitions -- for large portions of the
courses at FAU (and the development of added-value services on top of that to establish
formative assessment).

In the following we describe the information sources, the glossary extraction and curation
workflows and the \GloX tool ecosystem.

\section{Information Sources and Stakeholders}\label{sec:sources}

The main sources of information for the \FAUstairs domain model are the
following\ednote{MK: I am sure there are more, need to extend}:
\begin{enumerate}
\item the module descriptions in \campo: \url{https://campo.fau.de}
\item the course infrastructure and curriculum data on \studon: \url{https://studon.fau.de}
\item the course materials of the instructors. 
\end{enumerate}
The first two are available via the \DIP system, a centralized infrastructure and data
store for synchronization of the FAU learning administration systems provided by the FAU
RRZE.

The stakeholders in the \GloX process are\ednote{MK: there must be more; extend}
\begin{enumerate}
\item The \defemph{degree programs} represented by the program directors (the faculty
  member formally in charge), the program coordinators and maybe the study advisors.
\item The \defemph{departments} that host the degree programs, represented by their
  speakers and the department manager.
\item The instructors of the mandatory courses of a degree program; here we include the
  persons who organize the tutorials, homework assignments, and (summative) assessments.
\item The \defemph{\FAUstairs GloXers} -- three pairs of knowledge representation and
  domain specialists tasked with the \GloX process.
\end{enumerate}

\section{Workflow}\label{sec:main}

The \GloX workflow will consist of two large steps glossary extraction and glossary
curation, which we will sketch out in the following: 

\subsection{Glossary Extraction}\label{sec:glox}

In this step we examine the information sources from \cref{sec:sources} for
glossary-relevant information and export it into a curation format (most probably \FloDown
\cite{FloDown:on}).

The relevant steps are
\begin{enumerate}
\item \defemph{Concept Identification}: The domain specialists identify the key concepts
  in the information source
\item \defemph{Concept Annotation}: The concepts are annotated with
  \begin{enumerate}
  \item a \defemph{symbol} name (a system identifier), the concept in the source serves as the
    default verbalization. 
  \item (optionally) known \defemph{synonyms}, and 
  \item a \defemph{definition} (rigorous) or \defemph{concept documentation} (less
    rigorous description); both may be annotated by term references. 
  \end{enumerate}
\item \defemph{Translation}\ednote{MK: do we want to do this?; I think it will be
    necessary at least for Math, INF and the natural sciences}: Where the scientific
  discourse is international, the concept names are standardized to their English
  versions.
\end{enumerate}

\subsection{Domain Model Curation}\label{sec:gloc}

In this step we collect all the available glossaries, aggregate them into a coherent
domain model. The relevant steps are
\begin{enumerate}
\item \defemph{Collection}: The glossaries are collected and systematically organized into
  a modular collection, most probably managed and served by MathHub.info.
\item \defemph{Annotation}: The definitions are further annotated with term references
  into the joint domain model by the GloXers.
\item \defemph{Aggregation}: this is mainly a de-duplication step, which identifies
  possible duplicate concepts (probably by their definitions and/or usage patterns).
\item \defemph{Canonicalization}: The domain model is compared against the disciplinary
  learning ontologies, etc.
\end{enumerate}

\section{The \GloX Tool Ecosystem}\label{sec:glox}

We will start off the \GloX process with a glossary extraction tool for HTML module
descriptions (we assume that we can get them as HTML from the \DIP). We will have to
process hundreds of module descriptions over the course of the \FAUstairs project, so a
good workflow support for the three would be helpful.

\subsection{HTML \GloX}\label{sec:glox:html}

For concept identification (see above), the user selects a text region with a
(verbalization of) a key concept. For concept annotation, \GloX provides interaction
window that allows to enter the necessary data. \GloX should probably include Wikipedia or
LLM-based suggestions for the synonyms and definitions, possibly a concept spotter as
well. Also, we will need to include a snify-like workflow for the annotating the
definitions with term references.

It would be good if the HTML \GloX were not restricted to the module descriptions, but
could be used for arbitrary HTML documents; so that we could use it via pandoc for other
formats as well.

\subsection{Other \GloX{es}}

Many of the other information sources (see \cref{sec:sources}) are not (born as) HTML. It
will be critical to infiltrate the native workflows of the respective stakeholders to
lighten the workload (and possibly create alternative value). Other formats information
sources include
\begin{enumerate}
\item {\LaTeX}: here the \sTeX format~\cite{sTeX:github:on} is appropriate, and
  well-established.
\item MS PowerPoint: here we can build on
  CPoint~\cite{Kohlhase:SemanticInteractionDesignDiss:biblatex} to provide \GloX
  functionality; in fact we are starting a re-implementation in a Master's project, which
  should specialize in \GloX functionality initially.
\item MS Word: Here we can build on WOIDE (Word OMDoc IDE; see
  \cite{KohKoh:woide24,Adrian:bsc25}).
\item Text and MarkDown: here we can build on \FloDown \cite{FloDown:on}; and we already
  have a FloDown Console running for experimentation~\cite{FloDownConsole}.
\end{enumerate}
All of the tools export FTML (FlexiFormal Text Markup Language)\ednote{MK: how to cite
  it?}, which is at the heart of the KWARC toolchain.

Note that \GloX{ing} of course materials directly leads to semantically annotated course
documents, which could be used in \ALeA. In this case, we want to hold on to the annotated
course materials and provide additional added-value services. 

\subsection{Domain Model Curation}

For the domain model curation phase (see \cref{gloc}), we will (probably) use the
MathHub.info infrastructure; in particular
\begin{enumerate}
\item The GitLab \url{https://gl.mathhub.info} for versioned storage of the domain model
  (and possibly the anotated course materials). 
\item The \FLAMS system for serving the FTML and querying the triplestore
\item the new FloDown infrastructure to curate the domain model directly on MathHub.info
  in a dedicated curation interface.\ednote{MK: I am sure that this interface can be
    extended to sTeX, so that we can directly use it for MathHub curation as well. That
    would be a welcome synergy. Abhishek tells me that he is interested for Sophize.org as
    well.}
\end{enumerate}

\subsection{Development Model}\label{sec:devel}
As always, I would like the \GloX tool ecosystem to be developed in an iterative fashion: first draft
functionality soon, so that we can try and criticize, and advanced functionality/features
later. And of course, having a first mockup to show/demo to the program coordinators (they
need to have an idea what is coming) soon would be great.

\newpage
\begin{sloppypar}
\printbibliography
\end{sloppypar}
\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

% LocalWords:  GloXers de snify pandoc CPoint WOIDE MarkDown
